# Bot configuration example.
#
# Environment variables are supported using ${VAR_NAME} syntax.
# Example usage:
#   export BOT_TOKEN="your-bot-token"
#   export OPENAI_KEY="your-api-key"

# Telegram bot settings.
telegram:
  token: ${BOT_TOKEN}
  debug: false

# Storage configuration.
storage:
  type: bolt
  bolt:
    path: ./data/health-gpt.db

# LLM provider settings.
llm:
  provider: openai
  validate_responses: true
  openai:
    api_key: ${OPENAI_KEY}
    model: gpt-4o
    temperature: 0.1
    top_p: 1.0
    max_tokens: 2000
    socks_proxy: socks5://localhost:1080
    base_url: https://api.openai.com/v1

# Alternative LLM configuration examples:
#
# Anthropic:
# llm:
#   provider: anthropic
#   anthropic:
#     api_key: ${ANTHROPIC_KEY}
#     model: claude-3-7-sonnet-latest
#     top_p: 1.0
#     temperature: 0.7
#     max_tokens: 2000
#     socks_proxy: socks5://localhost:1080
#     base_url: https://api.anthropic.com/v1
#
# DeepSeek:
# llm:
#   provider: deepseek
#   deepseek:
#     api_key: ${DEEPSEEK_KEY}
#     model: deepseek-chat
#     temperature: 0.7
#     top_p: 1.0
#     max_tokens: 2000
#     socks_proxy: socks5://localhost:1080
#     base_url: https://api.deepseek.com
#
# Mistral:
# llm:
#   provider: mistral
#   mistral:
#     api_key: ${MISTRAL_KEY}
#     model: mistral-small-latest
#     temperature: 0.7
#     top_p: 1.0
#     max_tokens: 2000
#     socks_proxy: socks5://localhost:1080
#     base_url: https://api.mistral.ai
#
# Alternative storage examples:
#
# File system:
# storage:
#   type: fs
#   fs:
#     dir: ./data