# Bot configuration example.
#
# Environment variables are supported using ${VAR_NAME} syntax.
# Example usage:
#   export BOT_TOKEN="your-telegram-bot-token"
#   export OPENAI_KEY="your-openai-api-key"

# Telegram bot settings.
telegram:
  token: ${BOT_TOKEN}
  debug: false

# Storage configuration.
storage:
  type: bolt
  bolt:
    path: ./data/health-gpt.db

# LLM provider settings.
llm:
  provider: chatgpt
  chatgpt:
    api_key: ${OPENAI_KEY}
    model: gpt-4o
    temperature: 0.1
    top_p: 1.0
    max_tokens: 2000
    socks_proxy: socks5://localhost:1080
    base_url: https://api.openai.com/v1

# Alternative LLM configuration examples:
#
# Claude:
# llm:
#   provider: claude
#   claude:
#     api_key: ${CLAUDE_KEY}
#     model: claude-3-opus-20240229
#     temperature: 0.7
#     max_tokens: 2000
#
# DeepSeek:
# llm:
#   provider: deepseek
#   deepseek:
#     api_key: ${DEEPSEEK_KEY}
#     model: deepseek-chat
#     temperature: 0.7
#     top_p: 1.0
#     max_tokens: 2000
#     socks_proxy: socks5://localhost:1080
#     base_url: https://api.deepseek.com
#
# Alternative storage examples:
#
# File system:
# storage:
#   type: fs
#   fs:
#     dir: ./data