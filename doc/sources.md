1. Liu S., McCoy A. B., Wright A. Improving large language model applications in biomedicine with retrieval-augmented generation: a systematic review, meta-analysis, and clinical development guidelines // *Journal of the American Medical Informatics Association*. 2025. DOI: [10.1093/jamia/ocaf008](https://academic.oup.com/jamia/advance-article/doi/10.1093/jamia/ocaf008/7954485).

2. Zhang P., Shi J., Kamel Boulos M. N. Generative AI in Medicine and Healthcare: Moving Beyond the ‘Peak of Inflated Expectations’ // *Future Internet*. 2024. Vol. 16, No. 12. DOI: [10.3390/fi16120462](https://www.mdpi.com/1999-5903/16/12/462).

3. Singhal K., Tu T., Gottweis J. et al. Toward expert-level medical question answering with large language models // *Nature Medicine*. 2025. DOI: [10.1038/s41591-024-03423-7](https://www.nature.com/articles/s41591-024-03423-7).

4. Sohn J., Park Y., Yoon C. et al. Rationale-Guided Retrieval Augmented Generation for Medical Question Answering [Электронный ресурс] // *arXiv*. 2024. URL: [https://arxiv.org/abs/2411.00300](https://arxiv.org/abs/2411.00300) (дата обращения: 25.04.2025).

5. Lyu Y., Wu Z., Zhang L. et al. GP-GPT: Large Language Model for Gene-Phenotype Mapping [Электронный ресурс] // *arXiv*. 2024. URL: [https://arxiv.org/abs/2409.09825](https://arxiv.org/abs/2409.09825) (дата обращения: 25.04.2025).

6. Shorten C., Pierse C., Smith T. B. et al. StructuredRAG: JSON Response Formatting with Large Language Models [Электронный ресурс] // *arXiv*. 2024. URL: [https://arxiv.org/abs/2408.11061](https://arxiv.org/abs/2408.11061) (дата обращения: 25.04.2025).

7. Vaswani A., Shazeer N., Parmar N. et al. Attention is All You Need [Электронный ресурс] // *NeurIPS*. 2017. URL: [https://papers.nips.cc/paper/7181-attention-is-all-you-need](https://papers.nips.cc/paper/7181-attention-is-all-you-need) (дата обращения: 25.04.2025).

8. Kim J., Lee J. Strategic Data Ordering: Enhancing Large Language Model Performance through Curriculum Learning [Электронный ресурс] // *arXiv*. 2024. URL: [https://arxiv.org/abs/2405.07490](https://arxiv.org/abs/2405.07490) (дата обращения: 25.04.2025).

9. Fagnou E., Caillon P., Delattre B., Allauzen A. Chain and Causal Attention for Efficient Entity Tracking [Электронный ресурс] // *arXiv*. 2024. URL: [https://arxiv.org/abs/2410.05565](https://arxiv.org/abs/2410.05565) (дата обращения: 25.04.2025).

10. Chen Z., Liu Y., Shi L. et al. MDEval: Evaluating and Enhancing Markdown Awareness in Large Language Models [Электронный ресурс] // *arXiv*. 2025. URL: [https://arxiv.org/abs/2501.15000](https://arxiv.org/abs/2501.15000) (дата обращения: 25.04.2025).

11. Kepel D., Valogianni K. Autonomous Prompt Engineering in Large Language Models [Электронный ресурс] // *arXiv*. 2024. URL: [https://arxiv.org/abs/2407.11000](https://arxiv.org/abs/2407.11000) (дата обращения: 25.04.2025).

12. Padmaja C. V. R., Lakshminarayana S. Enhancing Language Models Through Prompt Engineering – A Survey // *IEEE International Conference on Intelligent Systems, Smart Grid and Technology (ICISSGT)*. 2024. P. 117–121. DOI: [10.1109/ICISSGT58904.2024.00033](https://ieeexplore.ieee.org/document/10345678).

13. Lamba D. The Role of Prompt Engineering in Improving Language Understanding and Generation // *International Journal for Multidisciplinary Research*. 2024. DOI: [10.36948/ijfmr.2024.v06i06.32232](https://www.ijfmr.com/research-paper.php?id=32232).

14. Wang J. et al. Prompt Engineering for Healthcare: Methodologies and Applications [Электронный ресурс] // *arXiv*. 2023. URL: [https://arxiv.org/abs/2304.14670](https://arxiv.org/abs/2304.14670) (дата обращения: 25.04.2025).

15. Ye Q., Axmed M., Pryzant R., Khani F. Prompt Engineering a Prompt Engineer [Электронный ресурс] // *arXiv*. 2023. URL: [https://arxiv.org/abs/2311.05661](https://arxiv.org/abs/2311.05661) (дата обращения: 25.04.2025).

16. Ravi S. S., Mielczarek B., Kannappan A., Kiela D., Qian R. Lynx: An Open Source Hallucination Evaluation Model [Электронный ресурс] // arXiv. 2024. URL: https://arxiv.org/abs/2407.08488 (дата обращения: 25.04.2025).

17. Son M., Won Y.-J., Lee S. Optimizing Large Language Models: A Deep Dive into Effective Prompt Engineering Techniques // *Applied Sciences*. 2025. Vol. 15, No. 3. DOI: [10.3390/app15031430](https://www.mdpi.com/2076-3417/15/3/1430).

18. Vatsal S., Dubey H. A Survey of Prompt Engineering Methods in Large Language Models for Different NLP Tasks [Электронный ресурс] // *arXiv*. 2024. URL: [https://arxiv.org/abs/2407.12994](https://arxiv.org/abs/2407.12994) (дата обращения: 25.04.2025).
